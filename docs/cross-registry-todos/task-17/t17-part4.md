<!-- file: docs/cross-registry-todos/task-17/t17-part4.md -->
<!-- version: 1.0.0 -->
<!-- guid: t17-observability-logging-part4-y9z0a1b2-c3d4 -->

# Task 17 Part 4: Log Aggregation Infrastructure

## Loki Deployment

### Loki Configuration

```yaml
# file: config/loki/loki-config.yaml
# version: 1.0.0
# guid: loki-configuration

auth_enabled: false

server:
  http_listen_port: 3100
  grpc_listen_port: 9096
  log_level: info

common:
  path_prefix: /loki
  storage:
    filesystem:
      chunks_directory: /loki/chunks
      rules_directory: /loki/rules
  replication_factor: 1
  ring:
    instance_addr: 127.0.0.1
    kvstore:
      store: inmemory

schema_config:
  configs:
    - from: 2020-10-24
      store: boltdb-shipper
      object_store: filesystem
      schema: v11
      index:
        prefix: index_
        period: 24h

storage_config:
  boltdb_shipper:
    active_index_directory: /loki/boltdb-shipper-active
    cache_location: /loki/boltdb-shipper-cache
    cache_ttl: 24h
    shared_store: filesystem
  filesystem:
    directory: /loki/chunks

compactor:
  working_directory: /loki/boltdb-shipper-compactor
  shared_store: filesystem

limits_config:
  enforce_metric_name: false
  reject_old_samples: true
  reject_old_samples_max_age: 168h
  ingestion_rate_mb: 16
  ingestion_burst_size_mb: 32
  per_stream_rate_limit: 10MB
  per_stream_rate_limit_burst: 20MB
  max_streams_per_user: 10000
  max_query_length: 721h
  max_query_parallelism: 32
  max_entries_limit_per_query: 10000

chunk_store_config:
  max_look_back_period: 0s

table_manager:
  retention_deletes_enabled: true
  retention_period: 720h

ruler:
  storage:
    type: local
    local:
      directory: /loki/rules
  rule_path: /loki/rules-temp
  alertmanager_url: http://alertmanager:9093
  ring:
    kvstore:
      store: inmemory
  enable_api: true

frontend:
  compress_responses: true
  max_outstanding_per_tenant: 2048
  log_queries_longer_than: 5s

query_range:
  align_queries_with_step: true
  max_retries: 5
  cache_results: true
  results_cache:
    cache:
      embedded_cache:
        enabled: true
        max_size_mb: 500
        ttl: 24h
```

### Loki Kubernetes Deployment

```yaml
# file: k8s/loki/deployment.yaml
# version: 1.0.0
# guid: loki-k8s-deployment

apiVersion: v1
kind: ConfigMap
metadata:
  name: loki-config
  namespace: observability
data:
  loki.yaml: |
    # Contents from loki-config.yaml above
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: loki
  namespace: observability
spec:
  serviceName: loki
  replicas: 3
  selector:
    matchLabels:
      app: loki
  template:
    metadata:
      labels:
        app: loki
    spec:
      containers:
      - name: loki
        image: grafana/loki:2.9.3
        args:
        - -config.file=/etc/loki/loki.yaml
        ports:
        - containerPort: 3100
          name: http
        - containerPort: 9096
          name: grpc
        volumeMounts:
        - name: config
          mountPath: /etc/loki
        - name: storage
          mountPath: /loki
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 2
            memory: 4Gi
        livenessProbe:
          httpGet:
            path: /ready
            port: 3100
          initialDelaySeconds: 45
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 3100
          initialDelaySeconds: 45
          periodSeconds: 10
      volumes:
      - name: config
        configMap:
          name: loki-config
  volumeClaimTemplates:
  - metadata:
      name: storage
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 50Gi
---
apiVersion: v1
kind: Service
metadata:
  name: loki
  namespace: observability
spec:
  type: ClusterIP
  ports:
  - port: 3100
    targetPort: 3100
    protocol: TCP
    name: http
  - port: 9096
    targetPort: 9096
    protocol: TCP
    name: grpc
  selector:
    app: loki
```

## Promtail Configuration

### Promtail Agent Setup

```yaml
# file: config/promtail/promtail-config.yaml
# version: 1.0.0
# guid: promtail-configuration

server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push
    tenant_id: tenant1
    batchwait: 1s
    batchsize: 1048576

scrape_configs:
  # Kubernetes pod logs
  - job_name: kubernetes-pods
    kubernetes_sd_configs:
      - role: pod
    pipeline_stages:
      # Extract log level
      - regex:
          expression: '.*level=(?P<level>\w+).*'
      - labels:
          level:

      # Extract trace ID
      - regex:
          expression: '.*trace_id=(?P<trace_id>[a-f0-9]+).*'
      - labels:
          trace_id:

      # Parse JSON logs
      - json:
          expressions:
            timestamp: timestamp
            level: level
            message: message
            service: service
            trace_id: trace_id
            span_id: span_id

      # Set timestamp
      - timestamp:
          source: timestamp
          format: RFC3339

      # Add labels
      - labels:
          level:
          service:

    relabel_configs:
      # Add namespace
      - source_labels: [__meta_kubernetes_namespace]
        target_label: namespace

      # Add pod name
      - source_labels: [__meta_kubernetes_pod_name]
        target_label: pod

      # Add container name
      - source_labels: [__meta_kubernetes_pod_container_name]
        target_label: container

      # Add app label
      - source_labels: [__meta_kubernetes_pod_label_app]
        target_label: app

      # Add environment from namespace
      - source_labels: [__meta_kubernetes_namespace]
        regex: '.*-(dev|staging|prod)$'
        target_label: environment

  # System logs
  - job_name: system
    static_configs:
      - targets:
          - localhost
        labels:
          job: varlogs
          __path__: /var/log/*.log
    pipeline_stages:
      - match:
          selector: '{job="varlogs"}'
          stages:
            - regex:
                expression: '(?P<timestamp>\w+ +\d+ \d+:\d+:\d+) (?P<hostname>\S+) (?P<process>\S+)(\[(?P<pid>\d+)\])?: (?P<message>.+)'
            - timestamp:
                source: timestamp
                format: Jan 02 15:04:05
            - labels:
                hostname:
                process:

  # Application logs from files
  - job_name: app-logs
    static_configs:
      - targets:
          - localhost
        labels:
          job: app-logs
          __path__: /var/log/app/*.json
    pipeline_stages:
      # Parse JSON
      - json:
          expressions:
            timestamp: timestamp
            level: level
            message: message
            service: service
            environment: environment
            trace_id: trace_id
            request_id: request_id

      # Extract additional fields
      - labels:
          level:
          service:
          environment:

      # Timestamp from log
      - timestamp:
          source: timestamp
          format: RFC3339
```

### Promtail DaemonSet

```yaml
# file: k8s/promtail/daemonset.yaml
# version: 1.0.0
# guid: promtail-k8s-daemonset

apiVersion: v1
kind: ServiceAccount
metadata:
  name: promtail
  namespace: observability
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: promtail
rules:
  - apiGroups: [""]
    resources:
      - nodes
      - nodes/proxy
      - services
      - endpoints
      - pods
    verbs: ["get", "watch", "list"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: promtail
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: promtail
subjects:
  - kind: ServiceAccount
    name: promtail
    namespace: observability
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: promtail-config
  namespace: observability
data:
  promtail.yaml: |
    # Contents from promtail-config.yaml above
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: promtail
  namespace: observability
spec:
  selector:
    matchLabels:
      app: promtail
  template:
    metadata:
      labels:
        app: promtail
    spec:
      serviceAccountName: promtail
      containers:
      - name: promtail
        image: grafana/promtail:2.9.3
        args:
        - -config.file=/etc/promtail/promtail.yaml
        env:
        - name: HOSTNAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        ports:
        - containerPort: 9080
          name: http
        volumeMounts:
        - name: config
          mountPath: /etc/promtail
        - name: positions
          mountPath: /tmp
        - name: varlog
          mountPath: /var/log
          readOnly: true
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 200m
            memory: 256Mi
      volumes:
      - name: config
        configMap:
          name: promtail-config
      - name: positions
        hostPath:
          path: /tmp/promtail-positions
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      tolerations:
      - effect: NoSchedule
        operator: Exists
```

## ELK Stack Alternative

### Elasticsearch Configuration

```yaml
# file: config/elasticsearch/elasticsearch.yml
# version: 1.0.0
# guid: elasticsearch-configuration

cluster.name: "logging-cluster"
network.host: 0.0.0.0

# Disable X-Pack security for development
xpack.security.enabled: false
xpack.monitoring.collection.enabled: true

# Node roles
node.roles: [ master, data, ingest ]

# Discovery
discovery.type: single-node

# Index settings
index.number_of_shards: 1
index.number_of_replicas: 1

# Memory settings
bootstrap.memory_lock: true

# Index lifecycle management
action.auto_create_index: true
indices.lifecycle.poll_interval: 10m

# Slow log thresholds
index.search.slowlog.threshold.query.warn: 10s
index.search.slowlog.threshold.query.info: 5s
index.search.slowlog.threshold.query.debug: 2s

index.indexing.slowlog.threshold.index.warn: 10s
index.indexing.slowlog.threshold.index.info: 5s
index.indexing.slowlog.threshold.index.debug: 2s

# Retention policies
indices.lifecycle.policies:
  logs-policy:
    phases:
      hot:
        min_age: 0ms
        actions:
          rollover:
            max_size: 50GB
            max_age: 1d
      warm:
        min_age: 7d
        actions:
          allocate:
            number_of_replicas: 1
          forcemerge:
            max_num_segments: 1
      cold:
        min_age: 30d
        actions:
          allocate:
            number_of_replicas: 0
          freeze: {}
      delete:
        min_age: 90d
        actions:
          delete: {}
```

### Logstash Pipeline

```ruby
# file: config/logstash/pipeline/logs.conf
# version: 1.0.0
# guid: logstash-pipeline

input {
  # Beats input
  beats {
    port => 5044
    codec => json
  }

  # TCP input for application logs
  tcp {
    port => 5000
    codec => json_lines
  }

  # HTTP input
  http {
    port => 8080
    codec => json
  }
}

filter {
  # Parse JSON logs
  if [message] {
    json {
      source => "message"
      target => "parsed"
    }
  }

  # Extract log level
  if [parsed][level] {
    mutate {
      add_field => { "log_level" => "%{[parsed][level]}" }
      uppercase => [ "log_level" ]
    }
  }

  # Extract trace context
  if [parsed][trace_id] {
    mutate {
      add_field => { "trace_id" => "%{[parsed][trace_id]}" }
    }
  }

  if [parsed][span_id] {
    mutate {
      add_field => { "span_id" => "%{[parsed][span_id]}" }
    }
  }

  # Parse timestamp
  if [parsed][timestamp] {
    date {
      match => [ "[parsed][timestamp]", "ISO8601" ]
      target => "@timestamp"
    }
  }

  # GeoIP enrichment
  if [parsed][remote_addr] {
    geoip {
      source => "[parsed][remote_addr]"
      target => "geoip"
    }
  }

  # User agent parsing
  if [parsed][user_agent] {
    useragent {
      source => "[parsed][user_agent]"
      target => "user_agent_parsed"
    }
  }

  # Error categorization
  if [log_level] == "ERROR" {
    if [parsed][error] =~ /timeout/i {
      mutate {
        add_field => { "error_category" => "timeout" }
      }
    } else if [parsed][error] =~ /connection/i {
      mutate {
        add_field => { "error_category" => "connection" }
      }
    } else if [parsed][error] =~ /database/i {
      mutate {
        add_field => { "error_category" => "database" }
      }
    } else {
      mutate {
        add_field => { "error_category" => "general" }
      }
    }
  }

  # Add metadata
  mutate {
    add_field => {
      "indexed_at" => "%{@timestamp}"
    }
  }

  # Remove unnecessary fields
  mutate {
    remove_field => [ "message", "host", "agent" ]
  }
}

output {
  # Elasticsearch output
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "logs-%{[parsed][service]}-%{+YYYY.MM.dd}"
    template_name => "logs"
    template_overwrite => true
  }

  # Stdout for debugging
  if [log_level] == "ERROR" {
    stdout {
      codec => rubydebug
    }
  }
}
```

### Kibana Configuration

```yaml
# file: config/kibana/kibana.yml
# version: 1.0.0
# guid: kibana-configuration

server.name: kibana
server.host: "0.0.0.0"
server.port: 5601

elasticsearch.hosts: ["http://elasticsearch:9200"]
elasticsearch.requestTimeout: 30000

# Monitoring
monitoring.ui.container.elasticsearch.enabled: true

# Logging
logging.dest: stdout
logging.verbose: false

# Index patterns
kibana.index: ".kibana"
kibana.defaultAppId: "discover"

# Security (disable for development)
xpack.security.enabled: false

# Saved objects
xpack.encryptedSavedObjects.encryptionKey: "something_at_least_32_characters_long"

# Alerting
xpack.alerting.enabled: true

# Visualization
xpack.canvas.enabled: true
xpack.graph.enabled: true
```

---

**Part 4 Complete**: Log aggregation infrastructure with Loki configuration for log storage using
BoltDB shipper and filesystem, retention policies for 30-day log retention, compactor for index
optimization, ruler for alerting rules, query frontend with caching, Loki Kubernetes StatefulSet
with 3 replicas and persistent volumes, Promtail configuration for scraping Kubernetes pod logs
with pipeline stages for JSON parsing and label extraction, system log collection, trace ID
correlation, Promtail DaemonSet with RBAC for cluster-wide log collection, ELK stack alternative
with Elasticsearch cluster configuration including index lifecycle management (hot/warm/cold/delete
phases), Logstash pipeline for log parsing with JSON decoding, GeoIP enrichment, user-agent parsing,
error categorization, and Elasticsearch output with daily indices, Kibana configuration for log
visualization and analysis. ✅

**Continue to Part 5** for log-based alerting rules, anomaly detection, and alert throttling.
